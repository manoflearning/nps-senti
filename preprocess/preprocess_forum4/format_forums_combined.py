from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Callable, Iterator, List, Dict, Iterable, Optional
import re

try:
    # ppomppu/theqoo ì „ì²˜ë¦¬ ê²°ê³¼ ì œë„ˆë ˆì´í„° ê°€ì ¸ì˜¤ê¸°
    from .format_ppomppu import iter_formatted_rows as iter_ppomppu_rows  # type: ignore
    from .format_theqoo import iter_formatted_rows as iter_theqoo_rows  # type: ignore
except ImportError:  # ì§ì ‘ ì‹¤í–‰í•  ë•Œ fallback
    from format_ppomppu import iter_formatted_rows as iter_ppomppu_rows  # type: ignore
    from format_theqoo import iter_formatted_rows as iter_theqoo_rows  # type: ignore


# ðŸ”¹ í”„ë¡œì íŠ¸ ë£¨íŠ¸: .../nps-senti
# __file__ = preprocess/preprocess_forum4/format_forums_combined.py
# parents[0] = preprocess_forum4, parents[1] = preprocess, parents[2] = nps-senti
BASE_DIR = Path(__file__).resolve().parents[2]

# ìž…ë ¥ ì›ë³¸ ë””ë ‰í† ë¦¬: ë£¨íŠ¸/data_crawl
DATA_DIR = BASE_DIR / "data_crawl"

# ì¶œë ¥ ë””ë ‰í† ë¦¬: ë£¨íŠ¸/preprocess/preprocessing_data
PREPROCESSING_DIR = BASE_DIR / "preprocess" / "preprocessing_data"


# ---------------------------------------------------------------------------
# ê³µí†µ ìœ í‹¸
# ---------------------------------------------------------------------------


def read_jsonl(path: Path) -> Iterator[dict]:
    """UTF-8 JSONLì„ í•œ ì¤„ì”© ì•ˆì „í•˜ê²Œ ì½ëŠ”ë‹¤."""
    if not path.exists():
        raise FileNotFoundError(path)
    with path.open("r", encoding="utf-8") as f:
        for line_no, raw in enumerate(f, 1):
            line = raw.strip()
            if not line:
                continue
            try:
                yield json.loads(line)
            except json.JSONDecodeError as err:
                raise ValueError(f"{path} line {line_no}: {err}") from err


def collect_comment_rows(
    source: str,
    post_id: str,
    title: str,
    published_at: str | None,
    base_lang: str,
    comments: Iterable[dict] | None,
    base_text: Optional[str] = None,
) -> Iterator[dict]:
    """
    forum.extra.forum.comments êµ¬ì¡°ë¥¼ ê³µí†µ ìŠ¤í‚¤ë§ˆ(comment)ë¡œ ë³€í™˜.

    ê³µí†µ ìŠ¤í‚¤ë§ˆ:
      - id                = f"{post_id}_{idx}"   (0ë¶€í„° ì‹œìž‘í•˜ëŠ” ëŒ“ê¸€ ì¸ë±ìŠ¤)
      - source
      - doc_type="comment"
      - parent_id         = post_id
      - title
      - lang
      - published_at      (ê²Œì‹œê¸€ ê¸°ì¤€)
      - text              (ì˜µì…˜: base_textê°€ ì£¼ì–´ì§€ë©´ ê²Œì‹œê¸€ ë³¸ë¬¸)
      - comment_index
      - comment_text
      - comment_publishedAt
    """
    if not comments:
        return
    for idx, comment in enumerate(comments):
        if not isinstance(comment, dict):
            continue

        comment_text = (comment.get("text") or "").strip()
        if not comment_text:
            continue

        # âœ… ë””ì‹œ/ìœ íŠœë¸Œ ìŠ¤íƒ€ì¼: comment id = "{post_id}_{idx}"
        comment_id = f"{post_id}_{idx}"
        comment_lang = comment.get("lang") or base_lang

        # í‚¤ ìˆœì„œë¥¼ ë³´ìž¥í•˜ê¸° ìœ„í•´ dictë¥¼ ìˆœì„œëŒ€ë¡œ ìƒì„±
        row: Dict[str, object] = {}
        row["id"] = comment_id
        row["source"] = source
        row["doc_type"] = "comment"
        row["parent_id"] = post_id
        row["title"] = title
        # mlbpark/ë³´ë°° ë“±: ëŒ“ê¸€ ë ˆì½”ë“œì—ë„ ê²Œì‹œê¸€ ë³¸ë¬¸ textë¥¼ ê³µìœ í•˜ê³  ì‹¶ì„ ë•Œ
        if base_text is not None:
            row["text"] = base_text
        row["lang"] = comment_lang
        row["published_at"] = published_at
        row["comment_index"] = idx
        row["comment_text"] = comment_text
        row["comment_publishedAt"] = comment.get("publishedAt")

        yield row


# ---------------------------------------------------------------------------
# mlbpark (ë””ì‹œ ìŠ¤íƒ€ì¼ë¡œ ë§žì¶”ê¸°)
# ---------------------------------------------------------------------------


def extract_post_body_mlbpark(post: dict) -> str:
    """
    mlbpark ì›ë³¸ post["text"] ì•ˆì—ëŠ”
      - ê²Œì‹œê¸€ ë³¸ë¬¸
      - ì‚¬ì´íŠ¸ í¬ë¡¬/ê¸°íƒ€
      - ëŒ“ê¸€ ë‚´ìš© (ì´ë¯¸ extra.forum.commentsì— ë”°ë¡œ ìžˆìŒ)
    ì´ ì„žì—¬ ìžˆì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ,

    1) extra.forum.comments[*].text ë¥¼ ì°¾ì•„ì„œ ì œê±°í•˜ê³ 
    2) ì¤„ë°”ê¿ˆ/ê³µë°±ì„ ê°€ë³ê²Œ ì •ë¦¬í•´ì„œ
    3) 'ê²Œì‹œê¸€ ë³¸ë¬¸'ì— ê°€ê¹Œìš´ í…ìŠ¤íŠ¸ë§Œ ë‚¨ê¸´ë‹¤.
    """
    text = (post.get("text") or "").strip()
    if not text:
        return ""

    extra = post.get("extra") or {}
    if not isinstance(extra, dict):
        extra = {}
    forum = extra.get("forum") or {}
    if not isinstance(forum, dict):
        forum = {}
    comments = forum.get("comments") or []
    if isinstance(comments, list):
        for c in comments:
            if not isinstance(c, dict):
                continue
            ct = (c.get("text") or "").strip()
            if not ct:
                continue
            if ct in text:
                text = text.replace(ct, "")

    # ì¤„ë°”ê¿ˆ/ê³µë°± ì •ë¦¬
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    text = re.sub(r"\n{3,}", "\n\n", text)

    # ê²Œì‹œê¸€ ë³¸ë¬¸ ëì— ë¶™ëŠ” 'ì¶”ì²œ N ê³µìœ ' í˜•íƒœ ì œê±°
    text = re.sub(r"\s*ì¶”ì²œ\s*\d+\s*ê³µìœ \s*$", "", text)

    return text.strip()


def iter_mlbpark_rows() -> Iterator[dict]:
    """
    mlbpark ì›ë³¸ forum_mlbpark.jsonl â†’ ê³µí†µ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜.

    post ë ˆì½”ë“œ:
      - id            = ê¸€ id
      - source        = "mlbpark"
      - doc_type      = "post"
      - parent_id     = None
      - title         = ì œëª©
      - text          = ëŒ“ê¸€ ì œê±°ëœ ê²Œì‹œê¸€ ë³¸ë¬¸
      - lang          = lang (ì—†ìœ¼ë©´ "ko")
      - published_at  = published_at ë˜ëŠ” date
      - comment_*     = None

    comment ë ˆì½”ë“œ:
      - id                = f"{post_id}_{idx}"
      - source            = "mlbpark"
      - doc_type          = "comment"
      - parent_id         = ì›ê¸€ id
      - title             = ì›ê¸€ ì œëª©
      - text              = ëŒ“ê¸€ ì œê±°ëœ ê²Œì‹œê¸€ ë³¸ë¬¸ (postì™€ ë™ì¼)
      - lang              = ëŒ“ê¸€ lang ë˜ëŠ” ê²Œì‹œê¸€ lang
      - published_at      = ê²Œì‹œê¸€ published_at (ë§¥ë½ìš©)
      - comment_index     = 0,1,2,...
      - comment_text      = ëŒ“ê¸€ ë‚´ìš©
      - comment_publishedAt = ëŒ“ê¸€ ì‹œê°(ìžˆìœ¼ë©´)
    """
    path = DATA_DIR / "forum_mlbpark.jsonl"
    for post in read_jsonl(path):
        post_id = str(post.get("id") or "").strip()
        if not post_id:
            continue

        title = (post.get("title") or "").strip()
        # ì œëª© ì •ë¦¬: ëì— ë¶™ì€ ' : MLBPARK' ë˜ëŠ” 'ì¶”ì²œ N ê³µìœ ' ì œê±°
        if title:
            title = re.sub(r"\s*:\s*MLBPARK\s*$", "", title, flags=re.I)
            title = re.sub(r"\s*ì¶”ì²œ\s*\d+\s*ê³µìœ \s*$", "", title)
            title = title.strip()
        lang = post.get("lang") or "ko"
        published_at = post.get("published_at") or post.get("date")

        extra = post.get("extra") or {}
        if not isinstance(extra, dict):
            extra = {}
        forum = extra.get("forum") or {}
        if not isinstance(forum, dict):
            forum = {}
        comments = forum.get("comments") or []
        if not isinstance(comments, list):
            comments = []

        # ë””ì‹œì™€ ë™ì¼í•œ ì»¨ì…‰: ëŒ“ê¸€ì„ ì œê±°í•œ ê²Œì‹œê¸€ ë³¸ë¬¸
        post_body = extract_post_body_mlbpark(post)

        # 1) ê²Œì‹œê¸€ ë ˆì½”ë“œ
        post_row: Dict[str, object] = {}
        post_row["id"] = post_id
        post_row["source"] = "mlbpark"
        post_row["doc_type"] = "post"
        post_row["parent_id"] = None
        post_row["title"] = title
        post_row["text"] = post_body
        post_row["lang"] = lang
        post_row["published_at"] = published_at
        post_row["comment_index"] = None
        post_row["comment_text"] = None
        post_row["comment_publishedAt"] = None

        yield post_row

        # 2) ëŒ“ê¸€ ë ˆì½”ë“œë“¤ (ëŒ“ê¸€ì˜ text = post_body, comment_text = ëŒ“ê¸€ ë³¸ë¬¸)
        yield from collect_comment_rows(
            "mlbpark",
            post_id,
            title,
            published_at,
            lang,
            comments,
            base_text=post_body,
        )


# ---------------------------------------------------------------------------
# bobaedream
# ---------------------------------------------------------------------------


def first_paragraph(text: str | None) -> str | None:
    if not text:
        return None
    normalized = text.replace("\r\n", "\n").replace("\r", "\n")
    snippet = normalized.split("\n\n", 1)[0].strip()
    return snippet or None


def iter_bobaedream_rows() -> Iterator[dict]:
    """
    bobaedream ì›ë³¸ forum_bobaedream.jsonl â†’ ê³µí†µ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜.

    comment ë ˆì½”ë“œ id ê·œì¹™:
      - id = f"{post_id}_{idx}"
    """
    path = DATA_DIR / "forum_bobaedream.jsonl"
    for post in read_jsonl(path):
        post_id = str(post.get("id") or "").strip()
        if not post_id:
            continue

        raw_title = (post.get("title") or "").strip()
        # "ì œëª© | ê¸°íƒ€" êµ¬ì¡°ì¼ ë•Œ, ì•žë¶€ë¶„ë§Œ ì‚¬ìš©
        title = raw_title.split("|", 1)[0].strip()
        lang = "ko"
        published_at = post.get("published_at") or post.get("date")
        text = first_paragraph(post.get("text"))

        # ê²Œì‹œê¸€ ë ˆì½”ë“œ
        post_row: Dict[str, object] = {}
        post_row["id"] = post_id
        post_row["source"] = "bobaedream"
        post_row["doc_type"] = "post"
        post_row["parent_id"] = None
        post_row["title"] = title
        post_row["text"] = text
        post_row["lang"] = lang
        post_row["published_at"] = published_at
        post_row["comment_index"] = None
        post_row["comment_text"] = None
        post_row["comment_publishedAt"] = None

        yield post_row

        # ëŒ“ê¸€ ë ˆì½”ë“œë„ ê²Œì‹œê¸€ ë³¸ë¬¸ì„ í•¨ê»˜ ê³µìœ í•˜ë„ë¡ í•¨ (ëŒ“ê¸€ì˜ `text` = post text)
        comments = (
            post.get("extra", {}).get("forum", {}).get("comments")
            if isinstance(post.get("extra"), dict)
            else []
        )
        yield from collect_comment_rows(
            "bobaedream", post_id, title, published_at, lang, comments, base_text=text
        )


# ---------------------------------------------------------------------------
# ppomppu / theqoo (ê°œë³„ í¬ë§·í„°ì—ì„œ ê°€ì ¸ì˜´)
# ---------------------------------------------------------------------------


FORMATTERS: Dict[str, Callable[[], Iterator[dict]]] = {
    "mlbpark": iter_mlbpark_rows,
    "ppomppu": iter_ppomppu_rows,
    "bobaedream": iter_bobaedream_rows,
    "theqoo": iter_theqoo_rows,
}


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Format forum_* JSONL files into a combined dataset."
    )
    parser.add_argument(
        "--sources",
        nargs="+",
        choices=sorted(FORMATTERS.keys()),
        help="Subset of forum sources to include (default: all).",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=PREPROCESSING_DIR / "new_forum_combined_comments_formatted.jsonl",
        help="Path for the combined JSONL output.",
    )
    return parser


def main(argv: List[str] | None = None) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)

    selected = (
        [src for src in args.sources if src in FORMATTERS]
        if args.sources
        else list(FORMATTERS.keys())
    )

    rows_written = 0
    args.output.parent.mkdir(parents=True, exist_ok=True)

    with args.output.open("w", encoding="utf-8") as f_out:
        for source in selected:
            formatter = FORMATTERS[source]
            for row in formatter():
                f_out.write(json.dumps(row, ensure_ascii=False) + "\n")
                rows_written += 1

    print(
        json.dumps(
            {
                "output": str(args.output),
                "sources": selected,
                "rows": rows_written,
            },
            ensure_ascii=False,
            indent=2,
        )
    )
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
