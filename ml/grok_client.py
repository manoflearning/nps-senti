# ml/grok_client.py
from __future__ import annotations

import json
import os
import re
from dataclasses import dataclass
from typing import Any, Dict, Optional

from openai import OpenAI
from openai.types import CompletionUsage
from dotenv import load_dotenv  # âœ… .env ì½ê¸°ìš©
from tenacity import retry, stop_after_attempt, wait_fixed  # retry

from ml.prompts import SYSTEM_PROMPT_NPS

SYSTEM_PROMPT = SYSTEM_PROMPT_NPS


@dataclass
class GrokConfig:
    api_key: str
    base_url: str
    model: str


def load_config() -> GrokConfig:
    load_dotenv()

    api_key = os.getenv("XAI_API_KEY") or os.getenv("GROK_API_KEY")
    if not api_key:
        raise RuntimeError(
            "xAI API key not found. í™˜ê²½ë³€ìˆ˜ XAI_API_KEY ë˜ëŠ” GROK_API_KEY ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”."
        )

    base_url = os.getenv("XAI_BASE_URL", "https://api.x.ai/v1")
    model = os.getenv("GROK_MODEL", "grok-4-fast-reasoning")

    return GrokConfig(api_key=api_key, base_url=base_url, model=model)


# ğŸ”¥ DCInside ê´€ë ¨ì„± ê°•ì œ ë³´ì •ìš© í‚¤ì›Œë“œ íŒ¨í„´
DCINSIDE_NPS_PATTERN = re.compile(
    r"(êµ­ë¯¼ì—°ê¸ˆ|ì—°ê¸ˆê³µë‹¨|\bNPS\b|national pension|ì—°ê¸ˆ|ê¸°ê¸ˆ|ê³ ê°ˆ|ìˆ˜ìµë¥ |ë³´í—˜ë£Œ|ìˆ˜ê¸‰|ë…¸í›„|ì†Œë“ëŒ€ì²´ìœ¨)",
    re.IGNORECASE,
)


class GrokClient:
    def __init__(self, config: Optional[GrokConfig] = None) -> None:
        self.config = config or load_config()
        self.client = OpenAI(
            base_url=self.config.base_url,
            api_key=self.config.api_key,
        )
        self.model = self.config.model

    def _extract_json(self, text: str) -> Dict[str, Any]:
        text = text.strip()
        if text.startswith("{") and text.endswith("}"):
            return json.loads(text)

        m = re.search(r"\{.*\}", text, re.DOTALL)
        if not m:
            raise ValueError(f"JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {text[:200]}")
        return json.loads(m.group(0))

    def _normalize_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        í™•ë¥ /ë¼ë²¨/ì„¤ëª… í›„ì²˜ë¦¬: 0~1 ë²”ìœ„, í•©â‰ˆ1, 0.00 í¬ë§·ì— ë§ê²Œ ì •ë¦¬.

        ğŸ”¥ ë³€ê²½ í•µì‹¬:
          - source == "dcinside" ì´ê³ , í…ìŠ¤íŠ¸ì— êµ­ë¯¼ì—°ê¸ˆ/ì—°ê¸ˆ/ê¸°ê¸ˆ/ê³ ê°ˆ/ë…¸í›„â€¦ í‚¤ì›Œë“œê°€ ìˆëŠ”ë°
            ëª¨ë¸ì´ is_related=falseë¥¼ ì¤€ ê²½ìš°, ê°•ì œë¡œ is_related=True ë¡œ ë³´ì •.
        """
        text = str(result.get("text") or "")
        source = str(result.get("source") or "")

        orig_is_related = bool(result.get("is_related", False))
        is_related = orig_is_related

        # âœ… DCInside ê´€ë ¨ì„± ë³´ì •
        if "dcinside" in source:
            if not is_related:
                if DCINSIDE_NPS_PATTERN.search(text):
                    # êµ­ë¯¼ì—°ê¸ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ ëª…ì‹œì ìœ¼ë¡œ ìˆìœ¼ë©´ ê°•ì œë¡œ ê´€ë ¨ìœ¼ë¡œ ë³¸ë‹¤.
                    is_related = True

        # is_related ìµœì¢… íŒë‹¨
        if not is_related:
            return {
                "is_related": False,
                "negative": 0.0,
                "neutral": 0.0,
                "positive": 0.0,
                "label": "ë¬´ê´€",
                "explanation": "êµ­ë¯¼ì—°ê¸ˆê³¼ ê´€ë ¨ ì—†ìŒ",
            }

        # ----- ì—¬ê¸°ë¶€í„°ëŠ” ê´€ë ¨(true)ì¸ ê²½ìš° í™•ë¥  ì •ê·œí™” -----
        neg = float(result.get("negative", 0.0) or 0.0)
        neu = float(result.get("neutral", 0.0) or 0.0)
        pos = float(result.get("positive", 0.0) or 0.0)

        neg = max(0.0, neg)
        neu = max(0.0, neu)
        pos = max(0.0, pos)

        # ì¶”ê°€: ìš•ì„¤/ëƒ‰ì†Œ ê°ì§€ (dcinside íŠ¹í™”, ì›¹ ìƒ˜í”Œ ê¸°ë°˜)
        curse_patterns = r"(ã……ã…‚|ã…ˆ|ì‹œë°œ|ì”¨ë°œ|ì§€ë„|fuck|shit|ì‚¬ê¸°|ê·¼ë“¤ê°‘|ì‹±ê¸€ë²™ê¸€|ã…‹ã…‹{2,})"
        if re.search(curse_patterns, text, re.IGNORECASE) and "dcinside" in source:
            neg += 0.15
            neg = min(1.0, neg)

        s = neg + neu + pos
        if s <= 0.0:
            neg, neu, pos = 0.0, 1.0, 0.0
        else:
            neg /= s
            neu /= s
            pos /= s

        neg = round(neg, 2)
        neu = round(neu, 2)
        pos = round(pos, 2)

        s2 = neg + neu + pos
        if s2 > 0:
            neg = round(neg / s2, 2)
            neu = round(neu / s2, 2)
            pos = round(pos / s2, 2)

        label = str(result.get("label", "")).strip()
        if label not in ("ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •", "ë¬´ê´€"):
            if neg >= neu and neg >= pos:
                label = "ë¶€ì •"
            elif pos >= neg and pos >= neu:
                label = "ê¸ì •"
            else:
                label = "ì¤‘ë¦½"

        explanation = str(result.get("explanation", "")).strip()
        if not explanation:
            if label == "ë¬´ê´€":
                explanation = "êµ­ë¯¼ì—°ê¸ˆê³¼ ê´€ë ¨ ì—†ìŒ"
            else:
                explanation = "êµ­ë¯¼ì—°ê¸ˆ ì œë„ì— ëŒ€í•œ ì „ë°˜ì ì¸ ê°ì„±ì„ ìš”ì•½í•œ ì„¤ëª…ì…ë‹ˆë‹¤."

        return {
            "is_related": True,
            "negative": float(f"{neg:.2f}"),
            "neutral": float(f"{neu:.2f}"),
            "positive": float(f"{pos:.2f}"),
            "label": label,
            "explanation": explanation,
        }

    def build_user_prompt(self, text: str, meta: Dict[str, Any]) -> str:
        source = meta.get("source")
        doc_type = meta.get("doc_type")
        lang = meta.get("lang")
        published_at = meta.get("published_at")
        identifier = meta.get("id")

        header_lines = [
            f"id: {identifier}",
            f"source: {source}",
            f"doc_type: {doc_type}",
            f"lang: {lang}",
            f"published_at: {published_at}",
            "",
            "ì•„ë˜ëŠ” ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
            "COMMENT_START",
            text,
            "COMMENT_END",
        ]
        return "\n".join(str(x) for x in header_lines)

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
    def analyze_sentiment(self, text: str, meta: Dict[str, Any]) -> Dict[str, Any]:
        if not text or not text.strip():
            return {
                "is_related": False,
                "negative": 0.0,
                "neutral": 0.0,
                "positive": 0.0,
                "label": "ë¬´ê´€",
                "explanation": "êµ­ë¯¼ì—°ê¸ˆê³¼ ê´€ë ¨ ì—†ìŒ",
            }

        user_content = self.build_user_prompt(text, meta)

        completion = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT_NPS},
                {"role": "user", "content": user_content},
            ],
            temperature=0.1,
            max_tokens=512,
        )

        raw = completion.choices[0].message.content or ""
        parsed = self._extract_json(raw)
        normalized = self._normalize_result(
            {**parsed, "text": text, "source": meta.get("source")}
        )
        return normalized
