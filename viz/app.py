from __future__ import annotations

import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

from nps_dashboard.config import DATA_PATH, ARTICLE_SOURCES, SENTIMENT_OPTIONS
from nps_dashboard.data import load_data
from nps_dashboard.wordcloud_tools import generate_wordcloud_image
from nps_dashboard.chart_helpers import (
    render_chart_with_selection,
    show_bucket_analysis_for_selection,
    show_grok_analysis_for_bucket,
    parse_date_selection_value,
    format_hour_label,
)


# ----------------------
# Helper Functions
# ----------------------
@st.cache_data(show_spinner="ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...")
def get_wordcloud_image(
    df_subset: pd.DataFrame,
    lang: str,
    min_freq: int,
):
    """
    ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ë¥¼ ìºì‹œí•´ì„œ
    - ìµœì´ˆ ì‹¤í–‰ ì‹œ ìƒì„±
    - ê°™ì€ df / lang / min_freq ì¡°í•©ì´ë©´ ìºì‹œëœ ê²°ê³¼ ìž¬ì‚¬ìš©
    """
    return generate_wordcloud_image(
        df_subset,
        lang=lang,
        min_freq=min_freq,
    )


def _build_article_sample_rows(day_articles: pd.DataFrame) -> list[dict[str, str]]:
    samples: list[dict[str, str]] = []
    if day_articles.empty:
        return samples

    for _, row in day_articles.head(5).iterrows():
        title = str(row.get("title") or "").strip()
        body = str(row.get("text") or "").strip()
        snippet = body[:220].replace("\n", " ")
        explanation_parts: list[str] = []
        if title:
            explanation_parts.append(f"ì œëª©: {title}")
        if snippet:
            explanation_parts.append(f"ë³¸ë¬¸: {snippet}")
        if not explanation_parts:
            continue
        samples.append(
            {
                "text": title or snippet[:120],
                "explanation": " | ".join(explanation_parts),
                "display_explanation": title or snippet[:120],
                "sentiment_label": row.get("source", "article"),
            }
        )

    return samples


# ----------------------
# 0. Streamlit ê¸°ë³¸ ì„¤ì •
# ----------------------
st.set_page_config(
    page_title="êµ­ë¯¼ì—°ê¸ˆ ì—¬ë¡  ëŒ€ì‹œë³´ë“œ",
    layout="wide",
)

st.title("êµ­ë¯¼ì—°ê¸ˆ ì¸í„°ë„· ì—¬ë¡  ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.subheader("by. FullRunAI Team")

# ----------------------
# 1. ë°ì´í„° ë¡œë”©
# ----------------------
df_raw = load_data(DATA_PATH)

# ------------------------------------------------------------
# ê¸€ë¡œë²Œ í•„í„°: ì†ŒìŠ¤ + ê¸°ê°„
# ------------------------------------------------------------
st.markdown("### âš™ï¸ í•„í„° (ì „ì²´ ì ìš©)")

available_sources_all = sorted(df_raw["source"].dropna().unique().tolist())
filter_left, filter_right, filter_meta = st.columns([1.6, 1.6, 1.8])

with filter_left:
    selected_sources_global = st.multiselect(
        "í¬í•¨í•  ì‚¬ì´íŠ¸",
        options=available_sources_all,
        default=available_sources_all,
    )

with filter_right:
    picked_range = None
    if "date" in df_raw.columns and df_raw["date"].notna().any():
        valid_dates = df_raw["date"].dropna()
        min_date = valid_dates.min().date()
        max_date = valid_dates.max().date()
        default_start = max_date - pd.Timedelta(days=90)
        default_start = max(default_start, min_date)
        picked_range = st.date_input(
            "ê¸°ê°„ ì„ íƒ (ê¸°ë³¸: ìµœê·¼ 90ì¼)",
            value=(default_start, max_date),
            min_value=min_date,
            max_value=max_date,
            key="global_date_range",
        )
    else:
        st.info("ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ê¸°ê°„ í•„í„°ë¥¼ ì ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ðŸ”¹ í•„í„° ì—†ìŒ(ì‚¬ì´íŠ¸ í•˜ë‚˜ë„ ì„ íƒ ì•ˆ í•¨)ì¸ ê²½ìš° ì•ˆë‚´ ë¬¸êµ¬
if not selected_sources_global:
    st.warning("ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ í•„í„°(ì‚¬ì´íŠ¸)ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# í•„í„° ì ìš© (ì „ì²´)
df_filtered = df_raw.copy()

if selected_sources_global:
    df_filtered = df_filtered[
        df_filtered["source"].isin(selected_sources_global)
    ].copy()

if picked_range and isinstance(picked_range, (list, tuple)) and len(picked_range) == 2:
    start_date, end_date = picked_range
    start_ts = pd.Timestamp(start_date)
    end_ts = (
        pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)
    )
    df_filtered = df_filtered[
        (df_filtered["date"].notna())
        & (df_filtered["date"].between(start_ts, end_ts, inclusive="both"))
    ].copy()

if df_filtered.empty:
    st.warning("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# ëŒ“ê¸€/ê¸°ì‚¬ ë°ì´í„° ë¶„ë¦¬
df_comments = df_filtered[~df_filtered["source"].isin(ARTICLE_SOURCES)].copy()
df_articles = df_filtered[df_filtered["source"].isin(ARTICLE_SOURCES)].copy()

# ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš©: dfëŠ” ëŒ“ê¸€ ë°ì´í„°
df = df_comments

if "date" in df_articles:
    df_articles["date_only"] = df_articles["date"].dt.date  # type: ignore

with filter_meta:
    st.metric("í•„í„° ì ìš© ëŒ“ê¸€ ìˆ˜", f"{len(df_comments):,}")
    st.caption(f"ê¸°ì‚¬(gdelt) {len(df_articles):,}ê±´ì€ ë³„ë„ ì„¹ì…˜ì—ì„œ ìš”ì•½")

# ============================================================
# 2. ì¢…í•© ë¶„ì„ (ë‹¨ë…)
# ============================================================
st.markdown("## 1ï¸âƒ£ ì¢…í•© ë¶„ì„ (ì „ì²´)")

total_comments = len(df)
if total_comments > 0:
    neg_ratio = (df["sentiment_label"] == "negative").mean()
    pos_ratio = (df["sentiment_label"] == "positive").mean()
else:
    neg_ratio = pos_ratio = 0.0

comment_data_available = total_comments > 0
article_count = len(df_articles)

col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("ì „ì²´ ë¶„ì„ ëŒ“ê¸€ ìˆ˜", f"{total_comments:,}")  # type: ignore
with col2:
    st.metric("ë¶€ì • ë¹„ìœ¨", f"{neg_ratio * 100:.1f}%")
with col3:
    st.metric("ê¸ì • ë¹„ìœ¨", f"{pos_ratio * 100:.1f}%")
with col4:
    st.metric("ê¸°ì‚¬(gdelt) ìˆ˜", article_count)

if not comment_data_available:
    st.info("ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ëž˜ ê¸°ì‚¬(gdelt) ì„¹ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.")

st.divider()

if comment_data_available:
    st.markdown("### ì „ì²´ ê°ì„±ë¶„ì„ ìš”ì•½ ì°¨íŠ¸")

    pie_col1, pie_col2 = st.columns(2)

    # (1) ì „ì²´ ê¸/ì¤‘ë¦½/ë¶€ì • ë¹„ìœ¨ íŒŒì´ì°¨íŠ¸
    with pie_col1:
        sent_pie = (
            df[df["sentiment_label"].isin(SENTIMENT_OPTIONS)]
            .groupby("sentiment_label")
            .size()
            .reindex(SENTIMENT_OPTIONS, fill_value=0)
            .rename("count")
            .reset_index()
        )

        pie1 = (
            alt.Chart(sent_pie)
            .mark_arc()
            .encode(
                theta="count:Q",
                color=alt.Color(
                    "sentiment_label:N",
                    title="ê°ì„±",
                    scale=alt.Scale(
                        domain=["negative", "neutral", "positive"],
                        range=["#e74c3c", "#bdc3c7", "#3498db"],
                    ),
                ),
                tooltip=["sentiment_label", "count"],
            )
            .properties(title="ì „ì²´ ê¸ì •Â·ì¤‘ë¦½Â·ë¶€ì • ë¹„ìœ¨", width=350, height=300)
        )
        st.altair_chart(pie1, width="content")

    # (2) ì‚¬ì´íŠ¸ë³„ ëŒ“ê¸€ ë¹„ìœ¨ íŒŒì´ì°¨íŠ¸
    with pie_col2:
        site_counts = (
            df[df["source"] != "gdelt"]["source"]
            .value_counts()
            .rename_axis("source")
            .reset_index(name="count")
        )
        site_order = [
            s for s in site_counts["source"].unique().tolist() if s != "gdelt"
        ]
        pie2 = (
            alt.Chart(site_counts)
            .mark_arc()
            .encode(
                theta="count:Q",
                color=alt.Color(
                    "source:N",
                    title="ì‚¬ì´íŠ¸",
                    scale=alt.Scale(domain=site_order),  # ðŸ”¹ ì—¬ê¸°ì„œ gdelt ë¼ë²¨ ì œê±°
                ),
                tooltip=["source", "count"],
            )
            .properties(title="ì‚¬ì´íŠ¸ë³„ ëŒ“ê¸€ ë¹„ìœ¨", width=350, height=300)
        )
        st.altair_chart(pie2, width="content")

    st.markdown("### ì›Œë“œí´ë¼ìš°ë“œ (í•œê¸€ / ì˜ì–´)")

    df_wc = df.copy()

    wc_ctrl1, wc_ctrl2, _ = st.columns([1, 1, 2])
    with wc_ctrl1:
        min_freq_ko = st.slider(
            "í•œê¸€ ìµœì†Œ ë“±ìž¥", min_value=1, max_value=20, value=3, step=1
        )
    with wc_ctrl2:
        min_freq_en = st.slider(
            "ì˜ì–´ ìµœì†Œ ë“±ìž¥", min_value=1, max_value=20, value=3, step=1
        )

    wc_col_ko, wc_col_en = st.columns([1, 1])

    with wc_col_ko:
        st.write("#### ì›Œë“œí´ë¼ìš°ë“œ (í•œê¸€)")
        img_ko = get_wordcloud_image(df_wc, lang="ko", min_freq=min_freq_ko)
        if img_ko is None:
            st.warning(
                "í•œê¸€ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í°íŠ¸ ë¯¸ì„¤ì¹˜/ê²½ë¡œ ë¬¸ì œ ë˜ëŠ” ë‹¨ì–´ ìˆ˜ ë¶€ì¡±)"
            )
        else:
            st.image(img_ko, width=430)

    with wc_col_en:
        st.write("#### Wordcloud (EN)")
        img_en = get_wordcloud_image(df_wc, lang="en", min_freq=min_freq_en)
        if img_en is None:
            st.warning("ì˜ì–´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“¤ ì¶©ë¶„í•œ ë‹¨ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.image(img_en, width=430)

    st.divider()

# ============================================================
# 3. ì¢…í•© ë¶„ì„ (ì‚¬ì´íŠ¸ë³„)
# ============================================================
if comment_data_available:
    st.markdown("## 2ï¸âƒ£ ì¢…í•© ë¶„ì„ (ì‚¬ì´íŠ¸ë³„)")

    GROUPS = {
        "videos": ["youtube"],
        "forums": ["bobaedream", "dcinside", "mlbpark", "theqoo"],
    }

    available_sources = sorted(df["source"].dropna().unique().tolist())
    GROUPS["forums"] = sorted(
        [s for s in available_sources if s not in set(GROUPS["videos"])]
    )
    df_sites = df.copy()

    if df_sites.empty:
        st.warning("ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        source_sent = (
            df_sites.groupby(["source", "sentiment_label"], observed=True)
            .size()
            .reset_index(name="count")
        )

        source_order = [
            s
            for s in (
                source_sent.groupby("source")["count"]
                .sum()
                .sort_values(ascending=False)
                .index.tolist()
            )
            if s != "gdelt"  # ðŸ”¹ gdelt ì œê±°
        ]

        stack_chart = (
            alt.Chart(source_sent)
            .transform_joinaggregate(total="sum(count)", groupby=["source"])
            .transform_calculate(pct="datum.count / datum.total")
            .mark_bar()
            .encode(
                x=alt.X(
                    "source:N",
                    title="ì‚¬ì´íŠ¸",
                    sort=source_order,
                    scale=alt.Scale(domain=source_order),
                ),
                y=alt.Y(
                    "count:Q",
                    stack="normalize",
                    title="ë¹„ìœ¨",
                    axis=alt.Axis(format="%"),
                ),
                color=alt.Color(
                    "sentiment_label:N",
                    title="ê°ì„±",
                    scale=alt.Scale(
                        domain=["negative", "neutral", "positive"],
                        range=["#e74c3c", "#bdc3c7", "#3498db"],
                    ),
                ),
                tooltip=[
                    alt.Tooltip("source:N", title="ì‚¬ì´íŠ¸"),
                    alt.Tooltip("sentiment_label:N", title="ê°ì„±"),
                    alt.Tooltip("count:Q", title="ëŒ“ê¸€ ìˆ˜"),
                    alt.Tooltip("total:Q", title="ì‚¬ì´íŠ¸ ì´ ëŒ“ê¸€"),
                    alt.Tooltip("pct:Q", title="ë¹„ìœ¨", format=".1%"),
                ],
            )
            .properties(
                height=340,
                title=alt.TitleParams(
                    "ì‚¬ì´íŠ¸ë³„ ê°ì„± ë ˆì´ë¸” ë¶„í¬ (100% ìŠ¤íƒ)", fontSize=16
                ),
            )
        )
        st.altair_chart(stack_chart, use_container_width=True)

    st.markdown("### ë¦¬ì»¤íŠ¸ ì°¨íŠ¸ (ì‚¬ì´íŠ¸ë³„ ë¶€ì •/ì¤‘ë¦½/ê¸ì • ê· í˜•)")

    if not df_sites.empty:
        df_likert = (
            df_sites[df_sites["sentiment_label"].isin(SENTIMENT_OPTIONS)]
            .groupby(["source", "sentiment_label"])
            .size()
            .unstack(fill_value=0)
            .reindex(columns=SENTIMENT_OPTIONS, fill_value=0)
        )

        df_likert["total"] = df_likert.sum(axis=1)
        max_total = df_likert["total"].max() or 1

        segments = []
        for src, row in df_likert.iterrows():
            total = int(row["total"]) or 1
            scale = total / max_total

            neg = (row.get("negative", 0) / total) * scale
            neu = (row.get("neutral", 0) / total) * scale
            pos = (row.get("positive", 0) / total) * scale

            neu_left = -neu / 2
            neu_right = neu / 2

            segments.append(
                {
                    "source": src,
                    "sentiment": "negative",
                    "x0": neu_left - neg,
                    "x1": neu_left,
                    "total": total,
                }
            )
            segments.append(
                {
                    "source": src,
                    "sentiment": "neutral",
                    "x0": neu_left,
                    "x1": neu_right,
                    "total": total,
                }
            )
            segments.append(
                {
                    "source": src,
                    "sentiment": "positive",
                    "x0": neu_right,
                    "x1": neu_right + pos,
                    "total": total,
                }
            )

        likert_df = pd.DataFrame(segments)
        likert_order = [
            s for s in likert_df["source"].unique().tolist() if s != "gdelt"
        ]

        likert_chart = (
            alt.Chart(likert_df)
            .mark_bar()
            .encode(
                y=alt.Y(
                    "source:N", title="ì‚¬ì´íŠ¸", scale=alt.Scale(domain=likert_order)
                ),
                x=alt.X(
                    "x0:Q",
                    title="â† ë¶€ì • / ì¤‘ë¦½ / ê¸ì • â†’",
                    scale=alt.Scale(domain=[-1, 1]),
                ),
                x2="x1:Q",
                color=alt.Color(
                    "sentiment:N",
                    title="ê°ì„±",
                    scale=alt.Scale(
                        domain=["negative", "neutral", "positive"],
                        range=["#e74c3c", "#bdc3c7", "#3498db"],
                    ),
                ),
                tooltip=["source", "sentiment", "total", "x0", "x1"],
            )
            .properties(height=320)
        )

        zero_line = (
            alt.Chart(pd.DataFrame({"x": [0]})).mark_rule(color="#666").encode(x="x:Q")
        )
        st.altair_chart(likert_chart + zero_line, use_container_width=True)
    else:
        st.info("ë¦¬ì»¤íŠ¸ ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ì–´ ì‚¬ì´íŠ¸ë³„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

st.divider()

# ============================================================
# 4. ê¸°ê°„ë³„ ë¶„ì„
# ============================================================
if comment_data_available:
    st.markdown("## 3ï¸âƒ£ ê¸°ê°„ë³„ ë¶„ì„")

    if "date" in df.columns and df["date"].notna().any():
        df_time = df[df["date"].notna()].copy()

        if df_time.empty:
            st.warning("í•´ë‹¹ ê¸°ê°„ì˜ ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df_sc = df_time.copy()

            prob_cols = [
                "sentiment.negative",
                "sentiment.neutral",
                "sentiment.positive",
            ]
            if all(c in df_sc.columns for c in prob_cols):
                for c in prob_cols:
                    df_sc[c] = pd.to_numeric(df_sc[c], errors="coerce").fillna(0.0)

                s = (
                    df_sc["sentiment.negative"]
                    + df_sc["sentiment.neutral"]
                    + df_sc["sentiment.positive"]
                )
                s = s.replace(0, np.nan)
                df_sc["sentiment.negative"] = (df_sc["sentiment.negative"] / s).fillna(
                    0.0
                )
                df_sc["sentiment.neutral"] = (df_sc["sentiment.neutral"] / s).fillna(
                    0.0
                )
                df_sc["sentiment.positive"] = (df_sc["sentiment.positive"] / s).fillna(
                    0.0
                )

                df_sc["sentiment_score"] = (
                    df_sc["sentiment.positive"] - df_sc["sentiment.negative"]
                ).astype("float32")
                df_sc["sentiment_score"] = df_sc["sentiment_score"].clip(-1.0, 1.0)
            else:
                SENTIMENT_TO_SCORE = {"negative": -1.0, "neutral": 0.0, "positive": 1.0}
                df_sc = df_sc[df_sc["sentiment_label"].isin(SENTIMENT_OPTIONS)].copy()
                df_sc["sentiment_score"] = (
                    df_sc["sentiment_label"].map(SENTIMENT_TO_SCORE).astype("float32")
                )

            df_sc["date_only"] = df_sc["date"].dt.date  # type: ignore
            if "hour" in df_sc.columns:
                df_sc["hour_int"] = (
                    pd.to_numeric(df_sc["hour"], errors="coerce")
                    .round()
                    .astype("Int64")
                )

            st.markdown("### ë‚ ì§œë³„ ê°ì„± ìŠ¤ì½”ì–´ (-1 ~ +1)")

            MA_DAYS = 7
            daily_score = (
                df_sc.dropna(subset=["date", "sentiment_score"])
                .groupby("date")["sentiment_score"]
                .agg(score="mean", n="size")
                .reset_index()
                .sort_values("date")
            )
            daily_score["ma"] = (
                daily_score["score"].rolling(MA_DAYS, min_periods=1).mean()
            )

            # âœ… í´ë¦­ ì„ íƒìš© selector
            date_selector = alt.selection_point(
                name="date_select",
                fields=["date"],
                nearest=True,
                on="click",
            )

            base = (
                alt.Chart(daily_score)
                .transform_calculate(
                    bar_color="datum.score > 0.05 ? '#3498db' : (datum.score < -0.05 ? '#e74c3c' : '#bdc3c7')"
                )
                .encode(x=alt.X("date:T", title="ë‚ ì§œ"))
            )

            bars = base.mark_bar().encode(
                y=alt.Y(
                    "score:Q",
                    title="ê°ì„± ìŠ¤ì½”ì–´(ê¸°ëŒ€ê°’)",
                    scale=alt.Scale(domain=[-1, 1]),
                ),
                color=alt.Color("bar_color:N", scale=None, legend=None),
                tooltip=[
                    alt.Tooltip("date:T"),
                    alt.Tooltip("score:Q"),
                    alt.Tooltip("ma:Q", title=f"MA({MA_DAYS})"),
                    alt.Tooltip("n:Q", title="í‘œë³¸ ìˆ˜"),
                ],
            )

            ma_line = base.mark_line(color="black").encode(y=alt.Y("ma:Q", title=None))
            zero = (
                alt.Chart(pd.DataFrame({"y": [0]}))
                .mark_rule(color="#666")
                .encode(y="y:Q")
            )

            daily_chart = (
                alt.layer(bars, ma_line, zero)
                .add_params(date_selector)
                .properties(height=320)
            )

            selected_date = render_chart_with_selection(
                daily_chart,  # type: ignore
                selection_name="date_select",
                selection_field="date",
                key="daily_sentiment_chart",
                parser=parse_date_selection_value,
            )

            show_bucket_analysis_for_selection(
                selected_value=selected_date,
                heading_template="#### ðŸ” {value} ë‚ ì§œ êµ¬ê°„ ë¶„ì„ (LLM ê¸°ë°˜ ì›¹ ì„œì¹˜)",
                df_comments=df_sc,
                mask_builder=lambda frame, value: frame["date_only"] == value,
                kind="daily_score",
            )

            st.markdown("### ì‹œê°„ëŒ€ë³„ ê°ì„± ìŠ¤ì½”ì–´ (-1 ~ +1)")

            MA_HOURS = 3
            hour_score = (
                df_sc.dropna(subset=["hour_int", "sentiment_score"])
                .groupby("hour_int")["sentiment_score"]
                .agg(score="mean", n="size")
                .reset_index()
                .rename(columns={"hour_int": "hour"})
            )
            hour_score["hour"] = hour_score["hour"].astype(int)
            hour_score = hour_score.sort_values("hour")
            hour_score["ma"] = (
                hour_score["score"].rolling(MA_HOURS, min_periods=1).mean()
            )

            hour_selector = alt.selection_point(
                name="hour_select",
                fields=["hour"],
                nearest=True,
                on="click",
            )

            base_h = (
                alt.Chart(hour_score)
                .transform_calculate(
                    bar_color="datum.score > 0.05 ? '#3498db' : (datum.score < -0.05 ? '#e74c3c' : '#bdc3c7')"
                )
                .encode(x=alt.X("hour:O", title="ì‹œê°„(ì‹œ)", sort=list(range(24))))
            )

            bars_h = base_h.mark_bar().encode(
                y=alt.Y(
                    "score:Q",
                    title="ê°ì„± ìŠ¤ì½”ì–´(ê¸°ëŒ€ê°’)",
                    scale=alt.Scale(domain=[-1, 1]),
                ),
                color=alt.Color("bar_color:N", scale=None, legend=None),
                tooltip=[
                    alt.Tooltip("hour:O"),
                    alt.Tooltip("score:Q"),
                    alt.Tooltip("ma:Q", title=f"MA({MA_HOURS})"),
                    alt.Tooltip("n:Q", title="í‘œë³¸ ìˆ˜"),
                ],
            )

            ma_line_h = base_h.mark_line(color="black").encode(y="ma:Q")
            zero_h = (
                alt.Chart(pd.DataFrame({"y": [0]}))
                .mark_rule(color="#666")
                .encode(y="y:Q")
            )

            hour_chart = (
                alt.layer(bars_h, ma_line_h, zero_h)
                .add_params(hour_selector)
                .properties(height=320)
            )

            selected_hour = render_chart_with_selection(
                hour_chart,  # type: ignore
                selection_name="hour_select",
                selection_field="hour",
                key="hourly_sentiment_chart",
                parser=lambda raw: int(raw),
            )

            show_bucket_analysis_for_selection(
                selected_value=selected_hour,
                heading_template="#### ðŸ” {value} êµ¬ê°„ ë¶„ì„ (LLM ê¸°ë°˜ ì›¹ ì„œì¹˜)",
                df_comments=df_sc,
                mask_builder=lambda frame, value: (frame["hour_int"] == value).fillna(
                    False
                ),
                kind="hourly_score",
                label_builder=format_hour_label,
            )

            st.markdown("### ëŒ“ê¸€ ìž‘ì„±ëŸ‰ ë³€í™” (ë‚ ì§œ / ì‹œê°„ëŒ€)")

            bar_col1, bar_col2 = st.columns(2)

            with bar_col1:
                daily_counts = df_time.groupby("date").size().reset_index(name="count")

                date_sel_volume = alt.selection_point(
                    name="date_volume_select",
                    fields=["date"],
                    on="click",
                )

                bar_date = (
                    alt.Chart(daily_counts)
                    .mark_bar()
                    .encode(
                        x=alt.X("date:T", title="ë‚ ì§œ"),
                        y=alt.Y(
                            "count:Q", title="ëŒ“ê¸€ ìˆ˜", scale=alt.Scale(domainMin=0)
                        ),
                        tooltip=["date", "count"],
                    )
                    .add_params(date_sel_volume)
                    .properties(height=300)
                    .interactive()
                )

                selected_date_vol = render_chart_with_selection(
                    bar_date,
                    selection_name="date_volume_select",
                    selection_field="date",
                    key="daily_volume_chart",
                    parser=parse_date_selection_value,
                )

                show_bucket_analysis_for_selection(
                    selected_value=selected_date_vol,
                    heading_template="#### ðŸ” {value} ë‚ ì§œ ëŒ“ê¸€ëŸ‰ ë¶„ì„ (LLM ê¸°ë°˜ ì›¹ ì„œì¹˜)",
                    df_comments=df_sc,
                    mask_builder=lambda frame, value: frame["date_only"] == value,
                    kind="daily_volume",
                )

            # ---- ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ìˆ˜ ----
            with bar_col2:
                if "hour" in df_time.columns:
                    hour_counts = (
                        df_time.groupby("hour").size().reset_index(name="count")
                    )

                    hour_sel_volume = alt.selection_point(
                        name="hour_volume_select",
                        fields=["hour"],
                        on="click",
                    )

                    bar_hour = (
                        alt.Chart(hour_counts)
                        .mark_bar()
                        .encode(
                            x=alt.X("hour:O", title="ì‹œê°„ëŒ€ (ì‹œ)"),
                            y=alt.Y(
                                "count:Q", title="ëŒ“ê¸€ ìˆ˜", scale=alt.Scale(domainMin=0)
                            ),
                            tooltip=["hour", "count"],
                        )
                        .add_params(hour_sel_volume)
                        .properties(height=300)
                        .interactive()
                    )

                    selected_hour_vol = render_chart_with_selection(
                        bar_hour,
                        selection_name="hour_volume_select",
                        selection_field="hour",
                        key="hourly_volume_chart",
                        parser=lambda raw: int(raw),
                    )

                    show_bucket_analysis_for_selection(
                        selected_value=selected_hour_vol,
                        heading_template="#### ðŸ§  {value} ëŒ“ê¸€ëŸ‰ ë¶„ì„ (LLM ê¸°ë°˜ ì›¹ ì„œì¹˜)",
                        df_comments=df_sc,
                        mask_builder=lambda frame, value: (
                            frame["hour_int"] == value
                        ).fillna(False),
                        kind="hourly_volume",
                        label_builder=format_hour_label,
                    )
                else:
                    st.info("ì‹œê°„ ì •ë³´ê°€ ì—†ì–´ ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ìˆ˜ë¥¼ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("published_at / date ì •ë³´ê°€ ì—†ì–´ ê¸°ê°„ë³„ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.info("ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ê°„ë³„ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

# ============================================================
# 5. ê¸°ì‚¬(gdelt) ìš”ì•½
# ============================================================
st.divider()
st.markdown("## ðŸ“° ê¸°ì‚¬ ì¸ì‚¬ì´íŠ¸ (gdelt)")

if df_articles.empty:
    st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬(gdelt) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    article_count = len(df_articles)
    date_min = df_articles["date"].min() if "date" in df_articles else None
    date_max = df_articles["date"].max() if "date" in df_articles else None

    col_a1, col_a2 = st.columns(2)
    with col_a1:
        st.metric("ê¸°ì‚¬ ìˆ˜", f"{article_count:,}")
    with col_a2:
        if pd.notna(date_min) and pd.notna(date_max):
            st.metric("ê¸°ê°„", f"{date_min.date()} ~ {date_max.date()}")
        else:
            st.metric("ê¸°ê°„", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")

    st.markdown("### ê¸°ì‚¬ ë°œí–‰ëŸ‰ ì¶”ì´")
    if "date" in df_articles and df_articles["date"].notna().any():
        daily_articles = (
            df_articles.groupby("date")
            .size()
            .reset_index(name="count")
            .sort_values("date")
        )

        article_sel = alt.selection_point(
            name="article_date_select",
            fields=["date"],
            on="click",
        )

        chart_articles = (
            alt.Chart(daily_articles)
            .mark_bar()
            .encode(
                x=alt.X("date:T", title="ë‚ ì§œ"),
                y=alt.Y("count:Q", title="ê¸°ì‚¬ ìˆ˜", scale=alt.Scale(domainMin=0)),
                tooltip=["date", "count"],
            )
            .add_params(article_sel)
            .properties(height=300)
            .interactive()
        )

        selected_article_date = render_chart_with_selection(
            chart_articles,
            selection_name="article_date_select",
            selection_field="date",
            key="article_volume_chart",
            parser=parse_date_selection_value,
        )

        if selected_article_date is not None:
            st.markdown(
                f"#### ðŸ” {selected_article_date} ê¸°ì‚¬ ë°œí–‰ëŸ‰ ë¶„ì„ (LLM ê¸°ë°˜ ì›¹ ì„œì¹˜)"
            )
            if "date" not in df_articles:
                st.info(
                    "ê¸°ì‚¬ ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ í•´ë‹¹ ë‚ ì§œ ê¸°ì‚¬ ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
            else:
                day_articles = df_articles[
                    df_articles["date"].dt.date == selected_article_date  # type: ignore
                ].copy()
                if day_articles.empty:
                    st.info("ì„ íƒí•œ ë‚ ì§œì˜ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                else:
                    stats_articles = {
                        "ê¸°ì‚¬ ìˆ˜": f"{len(day_articles):,}",
                        "ë°ì´í„° ìœ í˜•": "GDELT ê¸°ì‚¬ ë°œí–‰ëŸ‰ (ëŒ“ê¸€ ë°ì´í„° ì—†ìŒ)",
                    }
                    if "source" in day_articles:
                        top_sources = (
                            day_articles["source"].value_counts().head(3).index.tolist()
                        )
                        if top_sources:
                            stats_articles["ì£¼ìš” ì¶œì²˜"] = ", ".join(top_sources)
                    if "title" in day_articles:
                        candidate_titles = (
                            day_articles["title"].dropna().astype(str).str.strip()
                        )
                        top_titles = [t for t in candidate_titles if t][:3]
                        if top_titles:
                            stats_articles["ëŒ€í‘œ ê¸°ì‚¬ ì œëª©"] = " | ".join(top_titles)

                    sample_rows_articles = _build_article_sample_rows(day_articles)

                    show_grok_analysis_for_bucket(
                        kind="daily_article_volume",
                        label=str(selected_article_date),
                        df_comments=day_articles,
                        mask=None,
                        override_stats=stats_articles,
                        override_samples=sample_rows_articles,
                    )
    else:
        st.info("ê¸°ì‚¬ ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ì¶”ì´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if "sentiment_label" in df_articles:
        st.markdown("### ê¸°ì‚¬ ê°ì„± ë¶„í¬")
        art_sent = (
            df_articles[df_articles["sentiment_label"].isin(SENTIMENT_OPTIONS)]
            .groupby("sentiment_label")
            .size()
            .reindex(SENTIMENT_OPTIONS, fill_value=0)
            .reset_index(name="count")
        )
        pie_articles = (
            alt.Chart(art_sent)
            .mark_arc()
            .encode(
                theta="count:Q",
                color=alt.Color(
                    "sentiment_label:N",
                    scale=alt.Scale(
                        domain=["negative", "neutral", "positive"],
                        range=["#e74c3c", "#bdc3c7", "#3498db"],
                    ),
                ),
                tooltip=["sentiment_label", "count"],
            )
            .properties(width=350, height=300, title="ê¸°ì‚¬ ê°ì„± ë¹„ìœ¨")
        )
        st.altair_chart(pie_articles, width="content")
    else:
        st.info("ê¸°ì‚¬ ê°ì„± ë ˆì´ë¸”ì´ ì—†ì–´ ê°ì„± ë¶„í¬ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
